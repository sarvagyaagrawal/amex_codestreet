{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "riskfactor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uElpCt3oOvr2",
        "outputId": "228e5fa5-5fca-4da9-9c6e-11d69a6adae4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK0Q2tdDSCT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f88dfd-8c08-4697-af17-3c3671d86f78"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXHa10xcYqRK"
      },
      "source": [
        "def clean_data(data):\n",
        "  '''\n",
        "    This function will remove unwanted features which are not required during modelling\n",
        "  '''\n",
        "  data.drop(\"employ\", inplace=True, axis=1)\n",
        "  data.drop(\"ed\", inplace=True, axis=1)\n",
        "  data.drop(\"age\", inplace=True, axis=1)\n",
        "  data.drop(\"address\", inplace=True, axis=1)\n",
        "  data.drop(\"othdebt\", inplace=True, axis=1)\n",
        "\n",
        "  return data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqNNKVpsc4oK"
      },
      "source": [
        "def missing_values(data):\n",
        "\n",
        "  '''\n",
        "    THis function will fill the missing values of data in the dataset\n",
        "    Categorical type values will be filled using mode\n",
        "    Numerical type values will be filled using median\n",
        "  '''\n",
        "  data[\"income\"]=data[\"income\"].fillna(data[\"income\"].median())\n",
        "  data[\"debtinc\"]=data[\"debtinc\"].fillna(data[\"debtinc\"].median())\n",
        "  data[\"creddebt\"]=data[\"creddebt\"].fillna(data[\"creddebt\"].median())\n",
        "  data[\"savings\"]=data[\"savings\"].fillna(data[\"savings\"].median())\n",
        "  data[\"default\"]=data[\"default\"].fillna(data[\"default\"].mode()[0])\n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJepVs9RgPhJ"
      },
      "source": [
        "def feature_scaling(X_train):\n",
        "  ''' \n",
        "    Nomralisation:the data is scaled to a fixed range - usually 0 to 1\n",
        "    Standardization: the features will be rescaled so that they’ll have the properties of a standard normal distribution with \n",
        "                      μ=0 and σ=1\n",
        "    This function will be used for normalising the values so that one value does not have any greater effect on the model training.\n",
        "\n",
        "    X_train: 2-D numpy array, size=(length of dataset, number of features)\n",
        "   \n",
        "  '''\n",
        "  min_max_scaler = preprocessing.MinMaxScaler()\n",
        "  X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
        "\n",
        "  return X_train_minmax\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0psuaKpmkh3"
      },
      "source": [
        "def preprocessing_data(data):\n",
        "  '''\n",
        "    X: features\n",
        "    y: label\n",
        "  '''\n",
        "  data_cleaned=clean_data(data)\n",
        "  # data_filled=missing_values(data_cleaned)\n",
        "\n",
        "  X=data_cleaned.iloc[:700,:4]\n",
        "  y= data_cleaned.iloc[:700,4]\n",
        "\n",
        "  #dealing with imbalanced data\n",
        "  oversample = RandomOverSampler(random_state=0)\n",
        "  X, y = oversample.fit_resample(X, y)\n",
        "\n",
        "  #dividing the data into training and test data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "  \n",
        "  #feature scaling\n",
        "  # X_trainr=feature_scaling(X_train)\n",
        "  # X_test=feature_scaling(X_test)\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAuKa-3XMqKh"
      },
      "source": [
        "def wrapper():\n",
        "  ''' \n",
        "    This function will implement all other functions \n",
        "  '''\n",
        "  df=pd.read_csv(\"/content/drive/MyDrive/Amex Codestreet/bankloans.csv\")\n",
        "\n",
        "  print(df[\"default\"].value_counts(normalize=True))\n",
        "  X_train, X_test, y_train, y_test= preprocessing_data(df)\n",
        "  \n",
        "\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh-K7wujFAFx"
      },
      "source": [
        "## **Modelling and Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCrUkUHkGbmE"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_auc_score,cohen_kappa_score,confusion_matrix,roc_curve,balanced_accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI1Rzba7FF3v"
      },
      "source": [
        "def logistic_regression(X_train, X_test, y_train, y_test):\n",
        "  pipe = Pipeline([('scaler', preprocessing.MinMaxScaler()), ('lr',LogisticRegression())])\n",
        "  # clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
        "  # print(\"Training Accuracy:\", clf.score(X_train, y_train))\n",
        "  # print(\"Validation Accuracy:\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "  # parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1], 'solver':[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],'penalty':[\"l1\", \"l2\", \"elasticnet\", \"none\"]}\n",
        "  parameters = {'lr__C':[0.0000001,0.0001, 0.001, 0.01, 0.1, 1],'lr__solver':[\"newton-cg\", \"lbfgs\"],'lr__max_iter':[10000]}\n",
        "  grid_search = GridSearchCV(pipe, parameters, scoring='accuracy')\n",
        "  grid_fit = grid_search.fit(X_train, y_train)\n",
        "\n",
        "  best_par = grid_search.best_params_\n",
        "  print('Best params:', best_par) \n",
        "  \n",
        "  best_dt = grid_fit.best_estimator_\n",
        "\n",
        "  print(classification_report(y_test, best_dt.predict(X_test)))\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x-MTWGTiuEM"
      },
      "source": [
        "## Getting training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3c7wFtabzhb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0674fee1-7d91-43eb-e1af-ecb83bf66bc3"
      },
      "source": [
        "#calling wrapper function\n",
        "X_train, X_test, y_train, y_test= wrapper()\n",
        "print(X_train, X_test, y_train\n",
        "      , y_test)\n",
        "\n",
        "''' PIEPLINE'''\n",
        "# pipe = make_pipeline(MinMaxScaler(), LogisticRegression(C=8,random_state=7,fit_intercept=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0    0.738571\n",
            "1.0    0.261429\n",
            "Name: default, dtype: float64\n",
            "[[6.700000e+01 1.120000e+01 5.245296e+00 3.000000e+05]\n",
            " [7.000000e+01 1.200000e+01 4.334400e+00 3.000000e+04]\n",
            " [2.500000e+01 1.380000e+01 1.976850e+00 5.000000e+04]\n",
            " ...\n",
            " [2.400000e+01 1.560000e+01 1.636128e+00 3.700000e+05]\n",
            " [3.900000e+01 1.610000e+01 1.701609e+00 3.600000e+05]\n",
            " [9.100000e+01 2.520000e+01 2.316132e+00 3.000000e+04]] [[2.200000e+01 1.500000e+01 1.970100e+00 2.200000e+05]\n",
            " [4.300000e+01 1.320000e+01 3.042336e+00 2.000000e+05]\n",
            " [1.130000e+02 1.200000e+01 3.376440e+00 3.000000e+05]\n",
            " ...\n",
            " [6.700000e+01 1.320000e+01 3.741012e+00 6.000000e+04]\n",
            " [2.700000e+01 1.050000e+01 2.472120e+00 4.700000e+05]\n",
            " [1.130000e+02 2.600000e+00 9.871680e-01 1.400000e+05]] [0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0.\n",
            " 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0.\n",
            " 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
            " 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1.\n",
            " 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1.\n",
            " 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
            " 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0.\n",
            " 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
            " 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1.\n",
            " 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
            " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0.\n",
            " 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0.\n",
            " 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1.\n",
            " 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
            " 0. 1. 1. 0. 1. 1. 1.] [1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1.\n",
            " 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
            " 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' PIEPLINE'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhGJ3k-_E8UW"
      },
      "source": [
        "### **LOGISTIC REGRESSION CODE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAbx5qDzcEQF",
        "outputId": "da6960e0-1bfe-4fea-9917-2b673a88a036"
      },
      "source": [
        "logistic_regression(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'lr__C': 1, 'lr__max_iter': 10000, 'lr__solver': 'newton-cg'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.76      0.69      0.72       139\n",
            "         1.0       0.68      0.75      0.71       120\n",
            "\n",
            "    accuracy                           0.72       259\n",
            "   macro avg       0.72      0.72      0.72       259\n",
            "weighted avg       0.72      0.72      0.72       259\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czNACHSTiz6v"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmhZVZZtilmv"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "def support_vector(X_train, X_test, y_train, y_test):\n",
        "  pipe = Pipeline([('scaler', preprocessing.MinMaxScaler()), ('svc', SVC())])\n",
        "  # clf = SVC().fit(X_train, y_train)\n",
        "  # print(\"Training Accuracy:\", clf.score(X_train, y_train))\n",
        "  # print(\"Validation Accuracy:\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "  # parameters = {'C':[0.0001, 0.001, 0.01, 0.1, 1], 'solver':[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],'penalty':[\"l1\", \"l2\", \"elasticnet\", \"none\"]}\n",
        "  parameters={'svc__C': [0.001,0.01,0.1, 1, 10, 100], 'svc__gamma':['scale', 'auto'], 'svc__kernel': ['linear','rbf','poly', 'sigmoid'], 'svc__degree':[1,2,3,4]}\n",
        "  grid_search = GridSearchCV(pipe, parameters, scoring='accuracy')\n",
        "  grid_fit = grid_search.fit(X_train, y_train)\n",
        "\n",
        "  best_par = grid_search.best_params_\n",
        "  print('Best params:', best_par) \n",
        "  \n",
        "  best_dt = grid_fit.best_estimator_\n",
        "\n",
        "  print(classification_report(y_test, best_dt.predict(X_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZjeku34jYTE",
        "outputId": "ba70b4b5-408c-40e6-dfa7-98481ff3c894"
      },
      "source": [
        "support_vector(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'svc__C': 10, 'svc__degree': 1, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.75      0.68      0.72       139\n",
            "         1.0       0.67      0.74      0.70       120\n",
            "\n",
            "    accuracy                           0.71       259\n",
            "   macro avg       0.71      0.71      0.71       259\n",
            "weighted avg       0.71      0.71      0.71       259\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Snx2FmCkT_X"
      },
      "source": [
        "###**MLP**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1ACCH4Mkaz7"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "def multi_layer_perceptron(X_train, X_test, y_train, y_test):\n",
        "  pipe = Pipeline([('scaler', preprocessing.MinMaxScaler()), ('mlp', MLPClassifier())])\n",
        "  # clf = MLPClassifier().fit(X_train, y_train)\n",
        "  # print(\"Training Accuracy:\", clf.score(X_train, y_train))\n",
        "  # print(\"Validation Accuracy:\", accuracy_score(y_test, clf.predict(X_test)))\n",
        "\n",
        "  \n",
        "  parameters={'mlp__max_iter':[5000,1000,2000,3000], 'mlp__activation':['identity', 'logistic', 'tanh', 'relu'], 'mlp__hidden_layer_sizes':[(400,20)]}\n",
        "  grid_search = GridSearchCV(pipe, parameters, scoring='accuracy')\n",
        "  grid_fit = grid_search.fit(X_train, y_train)\n",
        "\n",
        "  best_par = grid_search.best_params_\n",
        "  print('Best params:', best_par) \n",
        "  \n",
        "  best_dt = grid_fit.best_estimator_\n",
        "\n",
        "  print(classification_report(y_test, best_dt.predict(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vO4f2Uv5kuv7",
        "outputId": "8ff9f58a-5f1f-4c3c-9db3-a89f117442aa"
      },
      "source": [
        "multi_layer_perceptron(X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'mlp__activation': 'relu', 'mlp__hidden_layer_sizes': (400, 20), 'mlp__max_iter': 3000}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.78      0.65      0.71       139\n",
            "         1.0       0.66      0.79      0.72       120\n",
            "\n",
            "    accuracy                           0.71       259\n",
            "   macro avg       0.72      0.72      0.71       259\n",
            "weighted avg       0.73      0.71      0.71       259\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH_9LUymvqWa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPrYuB2Ck4Ls"
      },
      "source": [
        "pipe = Pipeline([('scaler', preprocessing.MinMaxScaler()), ('mlp', MLPClassifier(activation= 'relu', hidden_layer_sizes= (400, 20), max_iter= 2000))])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR5uEylZ0Gcx",
        "outputId": "d19364ea-eb4b-4d3b-889a-a4ec93d35861"
      },
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
              "                ('mlp',\n",
              "                 MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
              "                               early_stopping=False, epsilon=1e-08,\n",
              "                               hidden_layer_sizes=(400, 20),\n",
              "                               learning_rate='constant',\n",
              "                               learning_rate_init=0.001, max_fun=15000,\n",
              "                               max_iter=2000, momentum=0.9, n_iter_no_change=10,\n",
              "                               nesterovs_momentum=True, power_t=0.5,\n",
              "                               random_state=None, shuffle=True, solver='adam',\n",
              "                               tol=0.0001, validation_fraction=0.1,\n",
              "                               verbose=False, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzcbP8WO2mYC",
        "outputId": "bf034b07-92d4-4f47-e61a-a628aac8dea9"
      },
      "source": [
        "pipe.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7297297297297297"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "wI7EQubZ2yi8",
        "outputId": "4705fcf5-f2e7-48c2-c105-0bcb58184b10"
      },
      "source": [
        "x=pipe.predict_proba([[21,12.9,1.3156,200000]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-1934691b7ea5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.3156\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAj8wPFqxsIQ"
      },
      "source": [
        "import pickle \n",
        "filename = 'final_model.sav'\n",
        "pickle.dump(pipe, open(filename, 'wb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8TtV0U4DKLw"
      },
      "source": [
        "### **Optimizing values and calculating financial plans** \n",
        "\n",
        "for savings to spending ratio , normalised savings, debt to income ratio\n",
        "\n",
        "###Using CVXPY Framework"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNTYYRFLFJTT"
      },
      "source": [
        "Links to refer:\n",
        "\n",
        "https://towardsdatascience.com/optimization-with-python-how-to-make-the-most-amount-of-money-with-the-least-amount-of-risk-1ebebf5b2f29\n",
        "\n",
        "\n",
        "https://www.cvxpy.org/examples/applications/max_entropy.html\n",
        "\n",
        "https://colab.research.google.com/github/cvxgrp/cvx_short_course/blob/master/applications/worst_case_analysis.ipynb\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioz6nP3wFpvi"
      },
      "source": [
        "Steps to follow:\n",
        "1. Define constraints\n",
        "2. Define Minimizing equation\n",
        "3. Use framework\n",
        "\n",
        "Constraints:\n",
        "\n",
        "spendings < income\n",
        "\n",
        "savings > spending\n",
        "\n",
        "savings>=income\n",
        "\n",
        "\n",
        "\n",
        "savings > debt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmd4m1Xatj9T"
      },
      "source": [
        "import cvxpy as cp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drwzJ5LCHiD_"
      },
      "source": [
        "import mosek"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moUMruFX4Cm8"
      },
      "source": [
        "\n",
        "def optimize_values(saving,debt,spending,income,minimum):\n",
        "  #please include minimum_amount as function parameter\n",
        "  x1=cp.Variable(pos=True)\n",
        "  x2=cp.Variable(pos=True)\n",
        "  \n",
        "  \n",
        "  constraint1=[saving*x1>=0,\n",
        "               saving*x1<=income,\n",
        "                saving*x1>=spending,\n",
        "              \n",
        "                x1>=0\n",
        "                \n",
        "  ]\n",
        "  constraint2=[\n",
        "               spending*x2+ +saving*x1<=income,\n",
        "               x2>=0.5,\n",
        "               spending*x1>=minimum_amount\n",
        "               x2<=1\n",
        "  ]\n",
        "\n",
        " \n",
        "  objective_fn1=x1\n",
        "  objective_fn2=x2\n",
        "  \n",
        "\n",
        "  problem3 = cp.Problem(cp.Maximize(objective_fn1),constraint1)\n",
        "  problem3.solve(verbose=True)\n",
        "\n",
        "  problem4 = cp.Problem(cp.Minimize(objective_fn2),constraint2)\n",
        "  problem4.solve()\n",
        "  assert problem3.is_dqcp()\n",
        "  assert problem4.is_dqcp()\n",
        " \n",
        "  \n",
        "  return x1.value, x2.value\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKDqNpO0tdn5",
        "outputId": "f899d395-06b3-47a4-a789-2ea67f06545c"
      },
      "source": [
        "print(cp.installed_solvers())\n",
        "saving=152474\n",
        "income=2100000\n",
        "debt=12.9*income\n",
        "spending=saving/10.316\n",
        "print(\"current spending\", spending)\n",
        "x,y=optimize_values(saving,debt,spending,income)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['CVXOPT', 'ECOS', 'ECOS_BB', 'GLPK', 'GLPK_MI', 'MOSEK', 'OSQP', 'SCS']\n",
            "current spending 14780.341217526171\n",
            "\n",
            "ECOS 2.0.7 - (C) embotech GmbH, Zurich Switzerland, 2012-15. Web: www.embotech.com/ECOS\n",
            "\n",
            "It     pcost       dcost      gap   pres   dres    k/t    mu     step   sigma     IR    |   BT\n",
            " 0  -4.472e+00  -5.349e+03  +8e+03  2e-06  4e-01  1e+00  1e+03    ---    ---    1  1  - |  -  - \n",
            " 1  -4.482e+00  -6.366e+01  +9e+01  2e-08  2e-02  1e-01  1e+01  0.9890  1e-04   0  0  0 |  0  0\n",
            " 2  -5.288e+00  -9.344e+00  +6e+00  1e-09  1e-03  2e-02  9e-01  0.9353  2e-04   0  0  0 |  0  0\n",
            " 3  -1.363e+01  -1.393e+01  +5e-01  1e-10  2e-04  8e-02  9e-02  0.9853  4e-02   0  0  0 |  0  0\n",
            " 4  -1.377e+01  -1.377e+01  +6e-03  1e-12  3e-06  1e-03  1e-03  0.9890  1e-04   0  0  0 |  0  0\n",
            " 5  -1.377e+01  -1.377e+01  +6e-05  2e-14  3e-08  1e-05  1e-05  0.9890  1e-04   0  0  0 |  0  0\n",
            " 6  -1.377e+01  -1.377e+01  +7e-07  2e-16  3e-10  1e-07  1e-07  0.9890  1e-04   0  0  0 |  0  0\n",
            " 7  -1.377e+01  -1.377e+01  +8e-09  1e-16  4e-12  1e-09  1e-09  0.9890  1e-04   0  0  0 |  0  0\n",
            "\n",
            "OPTIMAL (within feastol=3.8e-12, reltol=5.7e-10, abstol=7.8e-09).\n",
            "Runtime: 0.000288 seconds.\n",
            "\n",
            "x:  13.772839957178466\n",
            "y:  0.5000000012843347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEQGWjKhvrUv",
        "outputId": "540c3bde-1e86-4d84-cdce-8b438deaf5e0"
      },
      "source": [
        "print(\"Future Saving Required\",saving*x)\n",
        "print(\"Future Spending Required\",spending*y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Future Saving Required 271714.9591750198\n",
            "Future Spending Required 7390.170609119673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ-7TfdE7zRf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}